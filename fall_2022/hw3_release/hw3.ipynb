{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "*This notebook includes both coding and written questions. Please hand in this notebook file with all the outputs and your answers to the written questions.*\n",
    "\n",
    "This assignment covers linear filters, convolution and correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Convolutions\n",
    "### 1.1 Commutative Property (5 points)\n",
    "Recall that the convolution of an image $f:\\mathbb{R}^2\\rightarrow \\mathbb{R}$ and a kernel $h:\\mathbb{R}^2\\rightarrow\\mathbb{R}$ is defined as follows:\n",
    "$$(f*h)[m,n]=\\sum_{i=-\\infty}^\\infty\\sum_{j=-\\infty}^\\infty f[i,j]\\cdot h[m-i,n-j]$$\n",
    "\n",
    "Or equivalently,\n",
    "\\begin{align}\n",
    "(f*h)[m,n] &= \\sum_{i=-\\infty}^\\infty\\sum_{j=-\\infty}^\\infty h[i,j]\\cdot f[m-i,n-j]\\\\\n",
    "&= (h*f)[m,n]\n",
    "\\end{align}\n",
    "\n",
    "Show that this is true (i.e. prove that the convolution operator is commutative: $f*h = h*f$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** *Write your solution in this markdown cell. Please write your equations in [LaTex equations](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Typesetting%20Equations.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Shift Invariance (5 points)\n",
    "Let $f$ be a function $\\mathbb{R}^2\\rightarrow\\mathbb{R}$. Consider a system $f\\xrightarrow{s}g$, where $g=(f*h)$ with some kernel $h:\\mathbb{R}^2\\rightarrow\\mathbb{R}$. Also consider functions $f'[m,n] = f[m-m_0, n-n_0]$ and $g'[m,n] = g[m-m_0, n-n_0]$.  \n",
    "\n",
    "Show that $S$ defined by any kernel $h$ is a shift invariant system by showing that $g' = (f'*h)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** *Write your solution in this markdown cell. Please write your equations in [LaTex equations](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Typesetting%20Equations.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.3 Linearity (10 points)\n",
    "\n",
    "Recall that a system S is considered a linear system if and only if it satisfies the superposition property. In mathematical terms, a (function) S is a linear invariant system iff it satisfies:\n",
    "\n",
    "$$\n",
    "S\\{\\alpha f_1[n,m] + \\beta f_2[n,m]\\} = \\alpha S\\{f_1[n,m]\\} + \\beta S\\{f_2[n,m]\\}\n",
    "$$\n",
    "\n",
    "Let $f_1$ and $f_2$ be functions $\\mathbb{R}^2\\rightarrow\\mathbb{R}$. Consider a system $f\\xrightarrow{s}g$, where $g=(f*h)$ with some kernel $h:\\mathbb{R}^2\\rightarrow\\mathbb{R}$.  \n",
    "\n",
    "Prove that $S$ defined by any kernel $h$ is linear by showing that the superposition property holds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** *Write your solution in this markdown cell. Please write your equations in [LaTex equations](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Typesetting%20Equations.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Implementation (30 points)\n",
    "\n",
    "In this section, you will implement two versions of convolution:\n",
    "- `conv_nested`\n",
    "- `conv_fast`\n",
    "\n",
    "First, run the code cell below to load the image to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image as grayscale\n",
    "img = io.imread('dog.jpg', as_gray=True)\n",
    "\n",
    "# Show image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(\"Isn't he cute?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement the function **`conv_nested`** in **`filters.py`**. This is a naive implementation of convolution which uses 4 nested for-loops. It takes an image $f$ and a kernel $h$ as inputs and outputs the convolved image $(f*h)$ that has the same shape as the input image. This implementation should take a few seconds to run.\n",
    "\n",
    "*- Hint: It may be easier to implement $(h*f)$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first test your `conv_nested` function on a simple input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filters import conv_nested\n",
    "\n",
    "# Simple convolution kernel.\n",
    "kernel = np.array(\n",
    "[\n",
    "    [1,0,1],\n",
    "    [0,0,0],\n",
    "    [1,0,0]\n",
    "])\n",
    "\n",
    "# Create a test image: a white square in the middle\n",
    "test_img = np.zeros((9, 9))\n",
    "test_img[3:6, 3:6] = 1\n",
    "\n",
    "# Run your conv_nested function on the test image\n",
    "test_output = conv_nested(test_img, kernel)\n",
    "\n",
    "# Build the expected output\n",
    "expected_output = np.zeros((9, 9))\n",
    "expected_output[2:7, 2:7] = 1\n",
    "expected_output[5:, 5:] = 0\n",
    "expected_output[4, 2:5] = 2\n",
    "expected_output[2:5, 4] = 2\n",
    "expected_output[4, 4] = 3\n",
    "\n",
    "# Plot the test image\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(test_img)\n",
    "plt.title('Test image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot your convolved image\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(test_output)\n",
    "plt.title('Convolution')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the exepected output\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(expected_output)\n",
    "plt.title('Exepected output')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Test if the output matches expected output\n",
    "assert np.max(test_output - expected_output) < 1e-10, \"Your solution is not correct.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test your `conv_nested` function on a real image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filters import conv_nested\n",
    "\n",
    "# Simple convolution kernel.\n",
    "# Feel free to change the kernel to see different outputs.\n",
    "kernel = np.array(\n",
    "[\n",
    "    [1,0,-1],\n",
    "    [2,0,-2],\n",
    "    [1,0,-1]\n",
    "])\n",
    "\n",
    "out = conv_nested(img, kernel)\n",
    "\n",
    "# Plot original image\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot your convolved image\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(out)\n",
    "plt.title('Convolution')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot what you should get\n",
    "solution_img = io.imread('convolved_dog.png', as_gray=True)\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(solution_img)\n",
    "plt.title('What you should get')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us implement a more efficient version of convolution using array operations in numpy. As shown in the lecture, a convolution can be considered as a sliding window that computes sum of the pixel values weighted by the flipped kernel. The faster version will i) zero-pad an image, ii) flip the kernel horizontally and vertically, and iii) compute weighted sum of the neighborhood at each pixel.\n",
    "\n",
    "First, implement the function **`zero_pad`** in **`filters.py`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filters import zero_pad\n",
    "\n",
    "pad_width = 20 # width of the padding on the left and right\n",
    "pad_height = 40 # height of the padding on the top and bottom\n",
    "\n",
    "padded_img = zero_pad(img, pad_height, pad_width)\n",
    "\n",
    "# Plot your padded dog\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(padded_img)\n",
    "plt.title('Padded dog')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot what you should get\n",
    "solution_img = io.imread('padded_dog.jpg', as_gray=True)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(solution_img)\n",
    "plt.title('What you should get')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, complete the function **`conv_fast`** in **`filters.py`** using `zero_pad`. Run the code below to compare the outputs by the two implementations. `conv_fast` should run noticeably faster than `conv_nested`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filters import conv_fast\n",
    "\n",
    "t0 = time()\n",
    "out_fast = conv_fast(img, kernel)\n",
    "t1 = time()\n",
    "out_nested = conv_nested(img, kernel)\n",
    "t2 = time()\n",
    "\n",
    "# Compare the running time of the two implementations\n",
    "print(\"conv_nested: took %f seconds.\" % (t2 - t1))\n",
    "print(\"conv_fast: took %f seconds.\" % (t1 - t0))\n",
    "\n",
    "# Plot conv_nested output\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(out_nested)\n",
    "plt.title('conv_nested')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot conv_fast output\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(out_fast)\n",
    "plt.title('conv_fast')\n",
    "plt.axis('off')\n",
    "\n",
    "# Make sure that the two outputs are the same\n",
    "if not (np.max(out_fast - out_nested) < 1e-10):\n",
    "    print(\"Different outputs! Check your implementation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Cross-correlation\n",
    "\n",
    "Cross-correlation of an image $f$ with a template $g$ is defined as follows:\n",
    "$$(g ** f)[m,n]=\\sum_{i=-\\infty}^\\infty\\sum_{j=-\\infty}^\\infty g[i,j]\\cdot f[m + i,n + j]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Template Matching with Cross-correlation (12 points)\n",
    "Suppose that you are a clerk at a grocery store. One of your responsibilites is to check the shelves periodically and stock them up whenever there are sold-out items. You got tired of this laborious task and decided to build a computer vision system that keeps track of the items on the shelf.\n",
    "\n",
    "Luckily, you have learned in CS131 that cross-correlation can be used for template matching: a template $g$ is multiplied with regions of a larger image $f$ to measure how similar each region is to the template.\n",
    "\n",
    "The template of a product (`template.jpg`) and the image of shelf (`shelf.jpg`) is provided. We will use cross-correlation to find the product in the shelf.\n",
    "\n",
    "Implement **`cross_correlation`** function in **`filters.py`** and run the code below.\n",
    "\n",
    "*- Hint: you may use the `conv_fast` function you implemented in the previous question.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filters import cross_correlation\n",
    "\n",
    "# Load template and image in grayscale\n",
    "img = io.imread('shelf.jpg')\n",
    "img_gray = io.imread('shelf.jpg', as_gray=True)\n",
    "temp = io.imread('template.jpg')\n",
    "temp_gray = io.imread('template.jpg', as_gray=True)\n",
    "\n",
    "# Perform cross-correlation between the image and the template\n",
    "out = cross_correlation(img_gray, temp_gray)\n",
    "\n",
    "# Find the location with maximum similarity\n",
    "y,x = (np.unravel_index(out.argmax(), out.shape))\n",
    "\n",
    "# Display product template\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(temp)\n",
    "plt.title('Template')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display cross-correlation output\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(out)\n",
    "plt.title('Cross-correlation (white means more correlated)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display image\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(img)\n",
    "plt.title('Result (blue marker on the detected location)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Draw marker at detected location\n",
    "plt.plot(x, y, 'bx', ms=40, mew=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "How does the output of cross-correlation filter look? Explain what problems there might be with using a raw template as a filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** *Write your solution in this markdown cell.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.2 Zero-mean cross-correlation (6 points)\n",
    "A solution to this problem is to subtract the mean value of the template so that it has zero mean.\n",
    "\n",
    "Implement **`zero_mean_cross_correlation`** function in **`filters.py`** and run the code below.\n",
    "\n",
    "**If your implementation is correct, you should see the blue cross centered over the correct cereal box.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filters import zero_mean_cross_correlation\n",
    "\n",
    "# Perform cross-correlation between the image and the template\n",
    "out = zero_mean_cross_correlation(img_gray, temp_gray)\n",
    "\n",
    "# Find the location with maximum similarity\n",
    "y,x = np.unravel_index(out.argmax(), out.shape)\n",
    "\n",
    "# Display product template\n",
    "plt.figure(figsize=(30,20))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(temp)\n",
    "plt.title('Template')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display cross-correlation output\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(out)\n",
    "plt.title('Cross-correlation (white means more correlated)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display image\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(img)\n",
    "plt.title('Result (blue marker on the detected location)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Draw marker at detected location\n",
    "plt.plot(x, y, 'bx', ms=40, mew=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also determine whether the product is present with appropriate scaling and thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_product_on_shelf(shelf, product):\n",
    "    out = zero_mean_cross_correlation(shelf, product)\n",
    "    \n",
    "    # Scale output by the size of the template\n",
    "    out = out / float(product.shape[0]*product.shape[1])\n",
    "    \n",
    "    # Threshold output (this is arbitrary, you would need to tune the threshold for a real application)\n",
    "    out = out > 0.025\n",
    "    \n",
    "    if np.sum(out) > 0:\n",
    "        print('The product is on the shelf')\n",
    "    else:\n",
    "        print('The product is not on the shelf')\n",
    "\n",
    "# Load image of the shelf without the product\n",
    "img2 = io.imread('shelf_soldout.jpg')\n",
    "img2_gray = io.imread('shelf_soldout.jpg', as_gray=True)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "check_product_on_shelf(img_gray, temp_gray)\n",
    "\n",
    "plt.imshow(img2)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "check_product_on_shelf(img2_gray, temp_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.3 Normalized Cross-correlation (12 points)\n",
    "One day the light near the shelf goes out and the product tracker starts to malfunction. The `zero_mean_cross_correlation` is not robust to change in lighting condition. The code below demonstrates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filters import normalized_cross_correlation\n",
    "\n",
    "# Load image\n",
    "img = io.imread('shelf_dark.jpg')\n",
    "img_gray = io.imread('shelf_dark.jpg', as_gray=True)\n",
    "\n",
    "# Perform cross-correlation between the image and the template\n",
    "out = zero_mean_cross_correlation(img_gray, temp_gray)\n",
    "\n",
    "# Find the location with maximum similarity\n",
    "y, x = np.unravel_index(out.argmax(), out.shape)\n",
    "\n",
    "# Display image\n",
    "plt.imshow(img)\n",
    "plt.title('Result (red marker on the detected location)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Draw marker at detcted location\n",
    "plt.plot(x, y, 'rx', ms=25, mew=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A solution is to normalize the pixels of the image and template at every step before comparing them. This is called **normalized cross-correlation**.\n",
    "\n",
    "The mathematical definition for normalized cross-correlation of $f$ and template $g$ is:\n",
    "$$(g \\star f)[m,n]=\\sum_{i,j} \\frac{g[i, j]-\\overline{g}}{\\sigma_g} \\cdot \\frac{f[m + i, n + j]-\\overline{f_{m,n}}}{\\sigma_{f_{m,n}}}$$\n",
    "\n",
    "where:\n",
    "- $f_{m,n}$ is the patch image at position $(m,n)$\n",
    "- $\\overline{f_{m,n}}$ is the mean of the patch image $f_{m,n}$\n",
    "- $\\sigma_{f_{m,n}}$ is the standard deviation of the patch image $f_{m,n}$ \n",
    "- $\\overline{g}$ is the mean of the template $g$\n",
    "- $\\sigma_g$ is the standard deviation of the template $g$\n",
    "\n",
    "Implement **`normalized_cross_correlation`** function in **`filters.py`** and run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filters import normalized_cross_correlation\n",
    "\n",
    "# Perform normalized cross-correlation between the image and the template\n",
    "out = normalized_cross_correlation(img_gray, temp_gray)\n",
    "\n",
    "# Find the location with maximum similarity\n",
    "y, x = np.unravel_index(out.argmax(), out.shape)\n",
    "\n",
    "# Display image\n",
    "plt.imshow(img)\n",
    "plt.title('Result (red marker on the detected location)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Draw marker at detcted location\n",
    "plt.plot(x, y, 'rx', ms=25, mew=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Separable Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Theory (10 points)\n",
    "Consider an $M_1\\times{N_1}$ image $I$ and an $M_2\\times{N_2}$ filter $F$. A filter $F$ is **separable** if it can be written as a product of two 1D filters: $F=F_1F_2$.\n",
    "\n",
    "For example,\n",
    "$$F=\n",
    "\\begin{bmatrix}\n",
    "1 & -1 \\\\\n",
    "1 & -1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "can be written as a matrix product of\n",
    "$$F_1=\n",
    "\\begin{bmatrix}\n",
    "1  \\\\\n",
    "1\n",
    "\\end{bmatrix},\n",
    "F_2=\n",
    "\\begin{bmatrix}\n",
    "1 & -1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Therefore $F$ is a separable filter.\n",
    "\n",
    "Prove that for any separable filter $F=F_1F_2$,\n",
    "$$I*F=(I*F_1)*F_2$$\n",
    "where $*$ is the convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** *Write your solution in this markdown cell. Please write your equations in [LaTex equations](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Typesetting%20Equations.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Complexity comparison (10 points)\n",
    "Consider an $M_1\\times{N_1}$ image $I$ and an $M_2\\times{N_2}$ filter $F$ that is separable (i.e. $F=F_1F_2$).\n",
    "\n",
    "(i) How many multiplication operations do you need to do a direct 2D convolution (i.e. $I*F$)?<br>\n",
    "(ii) How many multiplication operations do you need to do 1D convolutions on rows and columns (i.e. $(I*F_1)*F_2$)?<br>\n",
    "(iii) Use Big-O notation, written with respet to the dimensions $M_1$, $N_1$, $M_2$, and $N_2$, to argue which one is more efficient in general: direct 2D convolution or two successive 1D convolutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** *Write your solution in this markdown cell. Please write your equations in [LaTex equations](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Typesetting%20Equations.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will empirically compare the running time of a separable 2D convolution and its equivalent two 1D convolutions. The Gaussian kernel, widely used for blurring images, is one example of a separable filter. Run the code below to see its effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "img = io.imread('dog.jpg', as_gray=True)\n",
    "\n",
    "# 5x5 Gaussian blur\n",
    "kernel = np.array([\n",
    "    [1,4,6,4,1],\n",
    "    [4,16,24,16,4],\n",
    "    [6,24,36,24,6],\n",
    "    [4,16,24,16,4],\n",
    "    [1,4,6,4,1]\n",
    "])\n",
    "\n",
    "t0 = time()\n",
    "out = conv_nested(img, kernel)\n",
    "t1 = time()\n",
    "t_normal = t1 - t0\n",
    "\n",
    "# Plot original image\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot convolved image\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(out)\n",
    "plt.title('Blurred')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code cell, define the two 1D arrays (`k1` and `k2`) whose product is equal to the Gaussian kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The kernel can be written as outer product of two 1D filters\n",
    "k1 = None  # shape (5, 1)\n",
    "k2 = None  # shape (1, 5)\n",
    "\n",
    "### YOUR CODE HERE\n",
    "pass\n",
    "### END YOUR CODE\n",
    "\n",
    "# Check if kernel is product of k1 and k2\n",
    "if not  np.all(k1 * k2 == kernel):\n",
    "    print('k1 * k2 is not equal to kernel')\n",
    "    \n",
    "assert k1.shape == (5, 1), \"k1 should have shape (5, 1)\"\n",
    "assert k2.shape == (1, 5), \"k2 should have shape (1, 5)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the two versions of convolution to the same image, and compare their running time. Note that the outputs of the two convolutions must be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform two convolutions using k1 and k2\n",
    "t0 = time()\n",
    "out_separable = conv_nested(img, k1)\n",
    "out_separable = conv_nested(out_separable, k2)\n",
    "t1 = time()\n",
    "t_separable = t1 - t0\n",
    "\n",
    "# Plot normal convolution image\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(out)\n",
    "plt.title('Normal convolution')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot separable convolution image\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(out_separable)\n",
    "plt.title('Separable convolution')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Normal convolution: took %f seconds.\" % (t_normal))\n",
    "print(\"Separable convolution: took %f seconds.\" % (t_separable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the two outputs are equal\n",
    "assert np.max(out_separable - out) < 1e-8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}