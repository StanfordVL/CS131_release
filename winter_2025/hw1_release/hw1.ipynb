{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "This homework will cover convolutions and Canny edge detectors.\n",
    "\n",
    "*This notebook includes both coding and written questions. Please hand in this notebook file with all the outputs and your answers to the written questions.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"CS131_release\"):\n",
    "    # Clone the repository if it doesn't already exist\n",
    "    !git clone https://github.com/StanfordVL/CS131_release.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd CS131_release/winter_2025/hw1_release/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary dependencies\n",
    "# (restart your runtime session if prompted to, and then re-run this cell)\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from time import time\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15.0, 12.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Part 1: Convolutions (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 Commutative Property (5 points)\n",
    "Recall that the convolution of an image $f:\\mathbb{R}^2\\rightarrow \\mathbb{R}$ and a kernel $h:\\mathbb{R}^2\\rightarrow\\mathbb{R}$ is defined as follows:\n",
    "$$(f*h)[m,n]=\\sum_{i=-\\infty}^\\infty\\sum_{j=-\\infty}^\\infty f[i,j]\\cdot h[m-i,n-j]$$\n",
    "\n",
    "Or equivalently,\n",
    "\\begin{align}\n",
    "(f*h)[m,n] &= \\sum_{i=-\\infty}^\\infty\\sum_{j=-\\infty}^\\infty h[i,j]\\cdot f[m-i,n-j]\\\\\n",
    "&= (h*f)[m,n]\n",
    "\\end{align}\n",
    "\n",
    "Show that this is true (i.e. prove that the convolution operator is commutative: $f*h = h*f$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** *Write your solution in this markdown cell. Please write your equations in [LaTex equations](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Typesetting%20Equations.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Shift Invariance (5 points)\n",
    "Let $f$ be a function $\\mathbb{R}^2\\rightarrow\\mathbb{R}$. Consider a system $f\\xrightarrow{s}g$, where $g=(f*h)$ with some kernel $h:\\mathbb{R}^2\\rightarrow\\mathbb{R}$. Also consider functions $f'[m,n] = f[m-m_0, n-n_0]$ and $g'[m,n] = g[m-m_0, n-n_0]$.  \n",
    "\n",
    "Show that $S$ defined by any kernel $h$ is a shift invariant system by showing that $g' = (f'*h)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** *Write your solution in this markdown cell. Please write your equations in [LaTex equations](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Typesetting%20Equations.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.3 Linearity (10 points)\n",
    "\n",
    "Recall that a system S is considered a linear system if and only if it satisfies the superposition property. In mathematical terms, a (function) S is a linear invariant system iff it satisfies:\n",
    "\n",
    "$$\n",
    "S\\{\\alpha f_1[n,m] + \\beta f_2[n,m]\\} = \\alpha S\\{f_1[n,m]\\} + \\beta S\\{f_2[n,m]\\}\n",
    "$$\n",
    "\n",
    "Let $f_1$ and $f_2$ be functions $\\mathbb{R}^2\\rightarrow\\mathbb{R}$. Consider a system $f\\xrightarrow{s}g$, where $g=(f*h)$ with some kernel $h:\\mathbb{R}^2\\rightarrow\\mathbb{R}$.  \n",
    "\n",
    "Prove that $S$ defined by any kernel $h$ is linear by showing that the superposition property holds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** *Write your solution in this markdown cell. Please write your equations in [LaTex equations](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Typesetting%20Equations.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Implementation (30 points)\n",
    "\n",
    "In this section, you will implement two versions of convolution:\n",
    "- `conv_nested`\n",
    "- `conv_fast`\n",
    "\n",
    "First, run the code cell below to load the image to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image as grayscale\n",
    "img = io.imread('dog.jpg', as_gray=True)\n",
    "\n",
    "# Show image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(\"Isn't he cute?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement the function **`conv_nested`** below. This is a naive implementation of convolution which uses 4 nested for-loops. It takes an image $f$ and a kernel $h$ as inputs and outputs the convolved image $(f*h)$ that has the same shape as the input image. This implementation should take a few seconds to run.\n",
    "\n",
    "*- Hint: It may be easier to implement $(h*f)$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first test your `conv_nested` function on a simple input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_nested(image, kernel):\n",
    "    \"\"\"A naive implementation of convolution filter.\n",
    "\n",
    "    This is a naive implementation of convolution using 4 nested for-loops.\n",
    "    This function computes convolution of an image with a kernel and outputs\n",
    "    the result that has the same shape as the input image.\n",
    "\n",
    "    Args:\n",
    "        image: numpy array of shape (Hi, Wi).\n",
    "        kernel: numpy array of shape (Hk, Wk). Dimensions will be odd.\n",
    "\n",
    "    Returns:\n",
    "        out: numpy array of shape (Hi, Wi).\n",
    "    \"\"\"\n",
    "    Hi, Wi = image.shape\n",
    "    Hk, Wk = kernel.shape\n",
    "    out = np.zeros((Hi, Wi))\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple convolution kernel.\n",
    "kernel = np.array(\n",
    "[\n",
    "    [1,0,1],\n",
    "    [0,0,0],\n",
    "    [1,0,0]\n",
    "])\n",
    "\n",
    "# Create a test image: a white square in the middle\n",
    "test_img = np.zeros((9, 9))\n",
    "test_img[3:6, 3:6] = 1\n",
    "\n",
    "# Run your conv_nested function on the test image\n",
    "test_output = conv_nested(test_img, kernel)\n",
    "\n",
    "# Build the expected output\n",
    "expected_output = np.zeros((9, 9))\n",
    "expected_output[2:7, 2:7] = 1\n",
    "expected_output[5:, 5:] = 0\n",
    "expected_output[4, 2:5] = 2\n",
    "expected_output[2:5, 4] = 2\n",
    "expected_output[4, 4] = 3\n",
    "\n",
    "# Plot the test image\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(test_img)\n",
    "plt.title('Test image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot your convolved image\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(test_output)\n",
    "plt.title('Convolution')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the exepected output\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(expected_output)\n",
    "plt.title('Exepected output')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Test if the output matches expected output\n",
    "assert np.max(test_output - expected_output) < 1e-10, \"Your solution is not correct.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test your `conv_nested` function on a real image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple convolution kernel.\n",
    "# Feel free to change the kernel to see different outputs.\n",
    "kernel = np.array(\n",
    "[\n",
    "    [1,0,-1],\n",
    "    [2,0,-2],\n",
    "    [1,0,-1]\n",
    "])\n",
    "\n",
    "out = conv_nested(img, kernel)\n",
    "\n",
    "# Plot original image\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot your convolved image\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(out)\n",
    "plt.title('Convolution')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot what you should get\n",
    "solution_img = io.imread('convolved_dog.png', as_gray=True)\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(solution_img)\n",
    "plt.title('What you should get')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us implement a more efficient version of convolution using array operations in numpy. As shown in the lecture, a convolution can be considered as a sliding window that computes sum of the pixel values weighted by the flipped kernel. The faster version will i) zero-pad an image, ii) flip the kernel horizontally and vertically, and iii) compute weighted sum of the neighborhood at each pixel.\n",
    "\n",
    "First, implement the function **`zero_pad`** below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(image, pad_height, pad_width):\n",
    "    \"\"\" Zero-pad an image.\n",
    "\n",
    "    Ex: a 1x1 image [[1]] with pad_height = 1, pad_width = 2 becomes:\n",
    "\n",
    "        [[0, 0, 0, 0, 0],\n",
    "         [0, 0, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 0]]         of shape (3, 5)\n",
    "\n",
    "    Args:\n",
    "        image: numpy array of shape (H, W).\n",
    "        pad_width: width of the zero padding (left and right padding).\n",
    "        pad_height: height of the zero padding (bottom and top padding).\n",
    "\n",
    "    Returns:\n",
    "        out: numpy array of shape (H+2*pad_height, W+2*pad_width).\n",
    "    \"\"\"\n",
    "\n",
    "    H, W = image.shape\n",
    "    out = None\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pad_width = 20 # width of the padding on the left and right\n",
    "pad_height = 40 # height of the padding on the top and bottom\n",
    "\n",
    "padded_img = zero_pad(img, pad_height, pad_width)\n",
    "\n",
    "# Plot your padded dog\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(padded_img)\n",
    "plt.title('Padded dog')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot what you should get\n",
    "solution_img = io.imread('padded_dog.jpg', as_gray=True)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(solution_img)\n",
    "plt.title('What you should get')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, complete the function **`conv_fast`** below using `zero_pad`. Run the code below to compare the outputs by the two implementations. `conv_fast` should run noticeably faster than `conv_nested`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_fast(image, kernel):\n",
    "    \"\"\" An efficient implementation of convolution filter.\n",
    "\n",
    "    This function uses element-wise multiplication and np.sum()\n",
    "    to efficiently compute weighted sum of neighborhood at each\n",
    "    pixel.\n",
    "\n",
    "    Hints:\n",
    "        - Use the zero_pad function you implemented above\n",
    "        - There should be two nested for-loops\n",
    "        - You may find np.flip() and np.sum() useful\n",
    "\n",
    "    Args:\n",
    "        image: numpy array of shape (Hi, Wi).\n",
    "        kernel: numpy array of shape (Hk, Wk). Dimensions will be odd.\n",
    "\n",
    "    Returns:\n",
    "        out: numpy array of shape (Hi, Wi).\n",
    "    \"\"\"\n",
    "    Hi, Wi = image.shape\n",
    "    Hk, Wk = kernel.shape\n",
    "    out = np.zeros((Hi, Wi))\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t0 = time()\n",
    "out_fast = conv_fast(img, kernel)\n",
    "t1 = time()\n",
    "out_nested = conv_nested(img, kernel)\n",
    "t2 = time()\n",
    "\n",
    "# Compare the running time of the two implementations\n",
    "print(\"conv_nested: took %f seconds.\" % (t2 - t1))\n",
    "print(\"conv_fast: took %f seconds.\" % (t1 - t0))\n",
    "\n",
    "# Plot conv_nested output\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(out_nested)\n",
    "plt.title('conv_nested')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot conv_fast output\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(out_fast)\n",
    "plt.title('conv_fast')\n",
    "plt.axis('off')\n",
    "\n",
    "# Make sure that the two outputs are the same\n",
    "if not (np.max(out_fast - out_nested) < 1e-10):\n",
    "    print(\"Different outputs! Check your implementation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Cross-correlation (30 points)\n",
    "\n",
    "Cross-correlation of an image $f$ with a template $g$ is defined as follows:\n",
    "$$(g ** f)[m,n]=\\sum_{i=-\\infty}^\\infty\\sum_{j=-\\infty}^\\infty g[i,j]\\cdot f[m + i,n + j]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Template Matching with Cross-correlation (12 points)\n",
    "Suppose that you are a clerk at a grocery store. One of your responsibilites is to check the shelves periodically and stock them up whenever there are sold-out items. You got tired of this laborious task and decided to build a computer vision system that keeps track of the items on the shelf.\n",
    "\n",
    "Luckily, you have learned in CS131 that cross-correlation can be used for template matching: a template $g$ is multiplied with regions of a larger image $f$ to measure how similar each region is to the template.\n",
    "\n",
    "The template of a product (`template.jpg`) and the image of shelf (`shelf.jpg`) is provided. We will use cross-correlation to find the product in the shelf.\n",
    "\n",
    "Implement **`cross_correlation`** function below and run the code below.\n",
    "\n",
    "*- Hint: you may use the `conv_fast` function you implemented in the previous question.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_correlation(f, g):\n",
    "    \"\"\" Cross-correlation of image f and template g.\n",
    "\n",
    "    Hint: use the conv_fast function defined above.\n",
    "\n",
    "    Args:\n",
    "        f: numpy array of shape (Hf, Wf).\n",
    "        g: numpy array of shape (Hg, Wg).\n",
    "\n",
    "    Returns:\n",
    "        out: numpy array of shape (Hf, Wf).\n",
    "    \"\"\"\n",
    "\n",
    "    out = None\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load template and image in grayscale\n",
    "img = io.imread('shelf.jpg')\n",
    "img_gray = io.imread('shelf.jpg', as_gray=True)\n",
    "temp = io.imread('template.jpg')\n",
    "temp_gray = io.imread('template.jpg', as_gray=True)\n",
    "\n",
    "# Perform cross-correlation between the image and the template\n",
    "out = cross_correlation(img_gray, temp_gray)\n",
    "\n",
    "# Find the location with maximum similarity\n",
    "y,x = (np.unravel_index(out.argmax(), out.shape))\n",
    "\n",
    "# Display product template\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(temp)\n",
    "plt.title('Template')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display cross-correlation output\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(out)\n",
    "plt.title('Cross-correlation (white means more correlated)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display image\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(img)\n",
    "plt.title('Result (blue marker on the detected location)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Draw marker at detected location\n",
    "plt.plot(x, y, 'bx', ms=40, mew=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "How does the output of cross-correlation filter look? Explain what problems there might be with using a raw template as a filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** *Write your solution in this markdown cell.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.2 Zero-mean cross-correlation (6 points)\n",
    "A solution to this problem is to subtract the mean value of the template so that it has zero mean.\n",
    "\n",
    "Implement **`zero_mean_cross_correlation`** function and run the code below.\n",
    "\n",
    "**If your implementation is correct, you should see the blue cross centered over the correct cereal box.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_mean_cross_correlation(f, g):\n",
    "    \"\"\" Zero-mean cross-correlation of image f and template g.\n",
    "\n",
    "    Subtract the mean of g from g so that its mean becomes zero.\n",
    "\n",
    "    Hint: you should look up useful numpy functions online for calculating the mean.\n",
    "\n",
    "    Args:\n",
    "        f: numpy array of shape (Hf, Wf).\n",
    "        g: numpy array of shape (Hg, Wg).\n",
    "\n",
    "    Returns:\n",
    "        out: numpy array of shape (Hf, Wf).\n",
    "    \"\"\"\n",
    "\n",
    "    out = None\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-correlation between the image and the template\n",
    "out = zero_mean_cross_correlation(img_gray, temp_gray)\n",
    "\n",
    "# Find the location with maximum similarity\n",
    "y,x = np.unravel_index(out.argmax(), out.shape)\n",
    "\n",
    "# Display product template\n",
    "plt.figure(figsize=(30,20))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(temp)\n",
    "plt.title('Template')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display cross-correlation output\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(out)\n",
    "plt.title('Cross-correlation (white means more correlated)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display image\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(img)\n",
    "plt.title('Result (blue marker on the detected location)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Draw marker at detected location\n",
    "plt.plot(x, y, 'bx', ms=40, mew=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also determine whether the product is present with appropriate scaling and thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_product_on_shelf(shelf, product):\n",
    "    out = zero_mean_cross_correlation(shelf, product)\n",
    "    \n",
    "    # Scale output by the size of the template\n",
    "    out = out / float(product.shape[0]*product.shape[1])\n",
    "    \n",
    "    # Threshold output (this is arbitrary, you would need to tune the threshold for a real application)\n",
    "    out = out > 0.025\n",
    "    \n",
    "    if np.sum(out) > 0:\n",
    "        print('The product is on the shelf')\n",
    "    else:\n",
    "        print('The product is not on the shelf')\n",
    "\n",
    "# Load image of the shelf without the product\n",
    "img2 = io.imread('shelf_soldout.jpg')\n",
    "img2_gray = io.imread('shelf_soldout.jpg', as_gray=True)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "check_product_on_shelf(img_gray, temp_gray)\n",
    "\n",
    "plt.imshow(img2)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "check_product_on_shelf(img2_gray, temp_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.3 Normalized Cross-correlation (12 points)\n",
    "One day the light near the shelf goes out and the product tracker starts to malfunction. The `zero_mean_cross_correlation` is not robust to change in lighting condition. The code below demonstrates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load image\n",
    "img = io.imread('shelf_dark.jpg')\n",
    "img_gray = io.imread('shelf_dark.jpg', as_gray=True)\n",
    "\n",
    "# Perform cross-correlation between the image and the template\n",
    "out = zero_mean_cross_correlation(img_gray, temp_gray)\n",
    "\n",
    "# Find the location with maximum similarity\n",
    "y, x = np.unravel_index(out.argmax(), out.shape)\n",
    "\n",
    "# Display image\n",
    "plt.imshow(img)\n",
    "plt.title('Result (red marker on the detected location)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Draw marker at detcted location\n",
    "plt.plot(x, y, 'rx', ms=25, mew=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A solution is to normalize the pixels of the image and template at every step before comparing them. This is called **normalized cross-correlation**.\n",
    "\n",
    "The mathematical definition for normalized cross-correlation of $f$ and template $g$ is:\n",
    "$$(g \\star f)[m,n]=\\sum_{i,j} \\frac{g[i, j]-\\overline{g}}{\\sigma_g} \\cdot \\frac{f[m + i, n + j]-\\overline{f_{m,n}}}{\\sigma_{f_{m,n}}}$$\n",
    "\n",
    "where:\n",
    "- $f_{m,n}$ is the patch image at position $(m,n)$\n",
    "- $\\overline{f_{m,n}}$ is the mean of the patch image $f_{m,n}$\n",
    "- $\\sigma_{f_{m,n}}$ is the standard deviation of the patch image $f_{m,n}$ \n",
    "- $\\overline{g}$ is the mean of the template $g$\n",
    "- $\\sigma_g$ is the standard deviation of the template $g$\n",
    "\n",
    "Implement the **`normalized_cross_correlation`** function and run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_correlation(f, g):\n",
    "    \"\"\" Normalized cross-correlation of image f and template g.\n",
    "\n",
    "    Normalize the subimage of f and the template g at each step\n",
    "    before computing the weighted sum of the two.\n",
    "\n",
    "    Hint: you should look up useful numpy functions online for calculating \n",
    "          the mean and standard deviation.\n",
    "\n",
    "    Args:\n",
    "        f: numpy array of shape (Hf, Wf).\n",
    "        g: numpy array of shape (Hg, Wg).\n",
    "\n",
    "    Returns:\n",
    "        out: numpy array of shape (Hf, Wf).\n",
    "    \"\"\"\n",
    "\n",
    "    out = None\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform normalized cross-correlation between the image and the template\n",
    "out = normalized_cross_correlation(img_gray, temp_gray)\n",
    "\n",
    "# Find the location with maximum similarity\n",
    "y, x = np.unravel_index(out.argmax(), out.shape)\n",
    "\n",
    "# Display image\n",
    "plt.imshow(img)\n",
    "plt.title('Result (red marker on the detected location)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Draw marker at detcted location\n",
    "plt.plot(x, y, 'rx', ms=25, mew=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Canny Edge Detector (85 points)\n",
    "In this part, you are going to implement a Canny edge detector. The Canny edge detection algorithm can be broken down in to five steps:\n",
    "1. Smoothing\n",
    "2. Finding gradients\n",
    "3. Non-maximum suppression\n",
    "4. Double thresholding\n",
    "5. Edge tracking by hysterisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Smoothing (10 points)\n",
    "#### Implementation (5 points)\n",
    "We first smooth the input image by convolving it with a Gaussian kernel. The equation for a Gaussian kernel of size $(2k+1)\\times(2k+1)$ is given by:\n",
    "\n",
    "$$h_{ij}=\\frac{1}{2\\pi\\sigma^2}\\exp{\\Bigl(-\\frac{(i-k)^2+(j-k)^2}{2\\sigma^2}\\Bigr)}, 0\\leq i,j < 2k+1$$\n",
    "\n",
    "Implement **`gaussian_kernel`** and run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(size, sigma):\n",
    "    \"\"\" Implementation of Gaussian Kernel.\n",
    "\n",
    "    This function follows the gaussian kernel formula,\n",
    "    and creates a kernel matrix.\n",
    "\n",
    "    Hints:\n",
    "    - Use np.pi and np.exp to compute pi and exp.\n",
    "\n",
    "    Args:\n",
    "        size: int of the size of output matrix.\n",
    "        sigma: float of sigma to calculate kernel.\n",
    "\n",
    "    Returns:\n",
    "        kernel: numpy array of shape (size, size).\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = np.zeros((size, size))\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 3x3 Gaussian kernel with std = 1\n",
    "kernel = gaussian_kernel(3, 1)\n",
    "kernel_test = np.array(\n",
    "    [[ 0.05854983, 0.09653235, 0.05854983],\n",
    "     [ 0.09653235, 0.15915494, 0.09653235],\n",
    "     [ 0.05854983, 0.09653235, 0.05854983]]\n",
    ")\n",
    "\n",
    "# Test Gaussian kernel\n",
    "if not np.allclose(kernel, kernel_test):\n",
    "    print('Incorrect values! Please check your implementation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement **`conv`** and run the code below. This time, ensure that you're using **edge** padding (as opposed to zero-padding, as done in `conv_fast`). \n",
    "\n",
    "Hint: Check out `np.pad`, and the various `mode`s that it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(image, kernel):\n",
    "    \"\"\" An implementation of convolution filter.\n",
    "\n",
    "    This function uses element-wise multiplication and np.sum()\n",
    "    to efficiently compute weighted sum of neighborhood at each\n",
    "    pixel.\n",
    "\n",
    "    Args:\n",
    "        image: numpy array of shape (Hi, Wi).\n",
    "        kernel: numpy array of shape (Hk, Wk).\n",
    "\n",
    "    Returns:\n",
    "        out: numpy array of shape (Hi, Wi).\n",
    "    \"\"\"\n",
    "    Hi, Wi = image.shape\n",
    "    Hk, Wk = kernel.shape\n",
    "    out = np.zeros((Hi, Wi))\n",
    "\n",
    "    # For this assignment, we will use edge values to pad the images.\n",
    "    # Zero padding will make derivatives at the image boundary very big,\n",
    "    # whereas we want to ignore the edges at the boundary.\n",
    "    pad_width0 = Hk // 2\n",
    "    pad_width1 = Wk // 2\n",
    "    pad_width = ((pad_width0,pad_width0),(pad_width1,pad_width1))\n",
    "    padded = np.pad(image, pad_width, mode='edge')\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different kernel_size and sigma\n",
    "kernel_size = 5\n",
    "sigma = 1.4\n",
    "\n",
    "# Load image\n",
    "img = io.imread('iguana.png', as_gray=True)\n",
    "\n",
    "# Define 5x5 Gaussian kernel with std = sigma\n",
    "kernel = gaussian_kernel(kernel_size, sigma)\n",
    "\n",
    "# Convolve image with kernel to achieve smoothed effect\n",
    "smoothed = conv(img, kernel)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(smoothed)\n",
    "plt.title('Smoothed image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question (5 points)\n",
    "What is the effect of changing kernel_size and sigma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** Write your solution in this markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Finding gradients (15 points)\n",
    "The gradient of a 2D scalar function $I:\\mathbb{R}^2\\rightarrow{\\mathbb{R}}$ in Cartesian coordinate is defined by:\n",
    "\n",
    "$$\\nabla{I(x,y)}=\\bigl[\\frac{\\partial{I}}{\\partial{x}},\\frac{\\partial{I}}{\\partial{y}}\\bigr],$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{I(x,y)}}{\\partial{x}}=\\lim_{\\Delta{x}\\to{0}}\\frac{I(x+\\Delta{x},y)-I(x,y)}{\\Delta{x}} \\\\\n",
    "\\frac{\\partial{I(x,y)}}{\\partial{y}}=\\lim_{\\Delta{y}\\to{0}}\\frac{I(x,y+\\Delta{y})-I(x,y)}{\\Delta{y}}.\n",
    "$$\n",
    "\n",
    "In case of images, we can approximate the partial derivatives by taking differences at one pixel intervals:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{I(x,y)}}{\\partial{x}}\\approx{\\frac{I(x+1,y)-I(x-1,y)}{2}} \\\\\n",
    "\\frac{\\partial{I(x,y)}}{\\partial{y}}\\approx{\\frac{I(x,y+1)-I(x,y-1)}{2}}\n",
    "$$\n",
    "\n",
    "Note that the partial derivatives can be computed by convolving the image $I$ with some appropriate kernels $D_x$ and $D_y$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{I}}{\\partial{x}}\\approx{I*D_x}=G_x \\\\\n",
    "\\frac{\\partial{I}}{\\partial{y}}\\approx{I*D_y}=G_y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation (5 points)\n",
    "Find the kernels $D_x$ and $D_y$ and implement **`partial_x`** and **`partial_y`** using `conv` defined below.\n",
    "\n",
    "*-Hint: Remeber that convolution flips the kernel.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def partial_x(img):\n",
    "    \"\"\" Computes partial x-derivative of input img.\n",
    "\n",
    "    Hints:\n",
    "        - You may use the conv function in defined in this file.\n",
    "\n",
    "    Args:\n",
    "        img: numpy array of shape (H, W).\n",
    "    Returns:\n",
    "        out: x-derivative image.\n",
    "    \"\"\"\n",
    "\n",
    "    out = None\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return out\n",
    "\n",
    "def partial_y(img):\n",
    "    \"\"\" Computes partial y-derivative of input img.\n",
    "\n",
    "    Hints:\n",
    "        - You may use the conv function in defined in this file.\n",
    "\n",
    "    Args:\n",
    "        img: numpy array of shape (H, W).\n",
    "    Returns:\n",
    "        out: y-derivative image.\n",
    "    \"\"\"\n",
    "\n",
    "    out = None\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test input\n",
    "I = np.array(\n",
    "    [[0, 0, 0],\n",
    "     [0, 1, 0],\n",
    "     [0, 0, 0]]\n",
    ")\n",
    "\n",
    "# Expected outputs\n",
    "I_x_test = np.array(\n",
    "    [[ 0, 0, 0],\n",
    "     [ 0.5, 0, -0.5],\n",
    "     [ 0, 0, 0]]\n",
    ")\n",
    "\n",
    "I_y_test = np.array(\n",
    "    [[ 0, 0.5, 0],\n",
    "     [ 0, 0, 0],\n",
    "     [ 0, -0.5, 0]]\n",
    ")\n",
    "\n",
    "# Compute partial derivatives\n",
    "I_x = partial_x(I)\n",
    "I_y = partial_y(I)\n",
    "\n",
    "# Test correctness of partial_x and partial_y\n",
    "if not np.all(I_x == I_x_test):\n",
    "    print('partial_x incorrect')\n",
    "    \n",
    "if not np.all(I_y == I_y_test):\n",
    "    print('partial_y incorrect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute partial derivatives of smoothed image\n",
    "Gx = partial_x(smoothed)\n",
    "Gy = partial_y(smoothed)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Gx)\n",
    "plt.title('Derivative in x direction')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Gy)\n",
    "plt.title('Derivative in y direction')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question (5 points)\n",
    "What is the reason for performing smoothing prior to computing the gradients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** Write your solution in this markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation (5 points)\n",
    "Now, we can compute the magnitude and direction of gradient with the two partial derivatives:\n",
    "\n",
    "$$\n",
    "G = \\sqrt{G_{x}^{2}+G_{y}^{2}} \\\\\n",
    "\\Theta = arctan\\bigl(\\frac{G_{y}}{G_{x}}\\bigr)\n",
    "$$\n",
    "\n",
    "Implement **`gradient`** below which takes in an image and outputs $G$ and $\\Theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gradient(img):\n",
    "    \"\"\" Returns gradient magnitude and direction of input img.\n",
    "\n",
    "    Args:\n",
    "        img: Grayscale image. Numpy array of shape (H, W).\n",
    "\n",
    "    Returns:\n",
    "        G: Magnitude of gradient at each pixel in img.\n",
    "            Numpy array of shape (H, W).\n",
    "        theta: Direction(in degrees, 0 <= theta < 360) of gradient\n",
    "            at each pixel in img. Numpy array of shape (H, W).\n",
    "\n",
    "    Hints:\n",
    "        - Use np.sqrt and np.arctan2 to calculate square root and arctan\n",
    "    \"\"\"\n",
    "    G = np.zeros(img.shape)\n",
    "    theta = np.zeros(img.shape)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return G, theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G, theta = gradient(smoothed)\n",
    "\n",
    "if not np.all(G >= 0):\n",
    "    print('Magnitude of gradients should be non-negative.')\n",
    "    \n",
    "if not np.all((theta >= 0) * (theta < 360)):\n",
    "    print('Direction of gradients should be in range 0 <= theta < 360')\n",
    "\n",
    "plt.imshow(G)\n",
    "plt.title('Gradient magnitude')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Non-maximum suppression (15 points)\n",
    "You should be able to see that the edges extracted from the gradient of the smoothed image are quite thick and blurry. The purpose of this step is to convert the \"blurred\" edges into \"sharp\" edges. Basically, this is done by preserving all local maxima in the gradient image and discarding everything else. The algorithm is for each pixel (x,y) in the gradient image:\n",
    "1. Round the gradient direction $\\Theta[y,x]$ to the nearest 45 degrees, corresponding to the use of an 8-connected neighbourhood.\n",
    "\n",
    "2. Compare the edge strength of the current pixel with the edge strength of the pixel in the positive and negative gradient directions. For example, if the gradient direction is south (theta=90), compare with the pixels to the north and south.\n",
    "\n",
    "3. If the edge strength of the current pixel is the largest; preserve the value of the edge strength. If not, suppress (i.e. remove) the value.\n",
    "\n",
    "Implement **`non_maximum_suppression`** below.\n",
    "\n",
    "We provide the correct output and the difference between it and your result for debugging purposes.  If you see white spots in the Difference image, you should check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_maximum_suppression(G, theta):\n",
    "    \"\"\" Performs non-maximum suppression.\n",
    "\n",
    "    This function performs non-maximum suppression along the direction\n",
    "    of gradient (theta) on the gradient magnitude image (G).\n",
    "\n",
    "    Args:\n",
    "        G: gradient magnitude image with shape of (H, W).\n",
    "        theta: direction of gradients with shape of (H, W).\n",
    "\n",
    "    Returns:\n",
    "        out: non-maxima suppressed image.\n",
    "    \"\"\"\n",
    "    H, W = G.shape\n",
    "    out = np.zeros((H, W))\n",
    "\n",
    "    # Round the gradient direction to the nearest 45 degrees\n",
    "    theta = np.floor((theta + 22.5) / 45) * 45\n",
    "\n",
    "    #print(G)\n",
    "    ### BEGIN YOUR CODE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test input\n",
    "g = np.array(\n",
    "    [[0.4, 0.5, 0.6],\n",
    "     [0.3, 0.5, 0.7],\n",
    "     [0.4, 0.5, 0.6]]\n",
    ")\n",
    "\n",
    "# Print out non-maximum suppressed output\n",
    "# varying theta\n",
    "for angle in range(0, 180, 45):\n",
    "    #print('Thetas:', angle)\n",
    "    t = np.ones((3, 3)) * angle # Initialize theta\n",
    "    print(non_maximum_suppression(g, t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms = non_maximum_suppression(G, theta)\n",
    "plt.imshow(nms)\n",
    "plt.title('Non-maximum suppressed')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(nms)\n",
    "plt.axis('off')\n",
    "plt.title('Your result')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "reference = np.load('references/iguana_non_max_suppressed.npy')\n",
    "plt.imshow(reference)\n",
    "plt.axis('off')\n",
    "plt.title('Reference')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(nms - reference)\n",
    "plt.title('Difference')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "np.amax(nms-reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Double Thresholding (20 points)\n",
    "\n",
    "The edge-pixels remaining after the non-maximum suppression step are (still) marked with their strength pixel-by-pixel. Many of these will probably be true edges in the image, but some may be caused by noise or color variations, for instance, due to rough surfaces. The simplest way to discern between these would be to use a threshold, so that only edges stronger that a certain value would be preserved. The Canny edge detection algorithm uses double thresholding. Edge pixels stronger than the high threshold are marked as strong; edge pixels weaker than the low threshold are suppressed and edge pixels between the two thresholds are marked as weak.\n",
    "\n",
    "Implement **`double_thresholding`** below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_thresholding(img, high, low):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        img: numpy array of shape (H, W) representing NMS edge response.\n",
    "        high: high threshold(float) for strong edges.\n",
    "        low: low threshold(float) for weak edges.\n",
    "\n",
    "    Returns:\n",
    "        strong_edges: Boolean array representing strong edges.\n",
    "            Strong edeges are the pixels with the values greater than\n",
    "            the higher threshold.\n",
    "        weak_edges: Boolean array representing weak edges.\n",
    "            Weak edges are the pixels with the values smaller or equal to the\n",
    "            higher threshold and greater than the lower threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    strong_edges = np.zeros(img.shape, dtype=bool)\n",
    "    weak_edges = np.zeros(img.shape, dtype=bool)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return strong_edges, weak_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "low_threshold = 0.02\n",
    "high_threshold = 0.03\n",
    "\n",
    "strong_edges, weak_edges = double_thresholding(nms, high_threshold, low_threshold)\n",
    "assert(np.sum(strong_edges & weak_edges) == 0)\n",
    "\n",
    "edges=strong_edges * 1.0 + weak_edges * 0.5\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(strong_edges)\n",
    "plt.title('Strong Edges')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(edges)\n",
    "plt.title('Strong+Weak Edges')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Edge tracking (15 points)\n",
    "\n",
    "Strong edges are interpreted as “certain edges”, and can immediately be included in the final edge image. Consider its neighbors iteratively then declare it an 'edge pixel' if it is connected to a 'strong edge pixel' directly or via pixels between Low and High. The logic is of course that noise and other small variations are unlikely to result in a strong edge (with proper adjustment of the threshold levels). Thus strong edges will (almost) only be due to true edges in the original image. The weak edges can either be due to true edges or noise/color variations. The latter type will probably be distributed independently of edges on the entire image, and thus only a small amount will be located adjacent to strong edges. Weak edges due to true edges are much more likely to be connected directly to strong edges.\n",
    "\n",
    "Implement **`link_edges`** below.\n",
    "\n",
    "We provide the correct output and the difference between it and your result for debugging purposes.  If you see white spots in the Difference image, you should check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a helper function for you to use:\n",
    "def get_neighbors(y, x, H, W):\n",
    "    \"\"\" Return indices of valid neighbors of (y, x).\n",
    "\n",
    "    Return indices of all the valid neighbors of (y, x) in an array of\n",
    "    shape (H, W). An index (i, j) of a valid neighbor should satisfy\n",
    "    the following:\n",
    "        1. i >= 0 and i < H\n",
    "        2. j >= 0 and j < W\n",
    "        3. (i, j) != (y, x)\n",
    "\n",
    "    Args:\n",
    "        y, x: location of the pixel.\n",
    "        H, W: size of the image.\n",
    "    Returns:\n",
    "        neighbors: list of indices of neighboring pixels [(i, j)].\n",
    "    \"\"\"\n",
    "    neighbors = []\n",
    "\n",
    "    for i in (y-1, y, y+1):\n",
    "        for j in (x-1, x, x+1):\n",
    "            if i >= 0 and i < H and j >= 0 and j < W:\n",
    "                if (i == y and j == x):\n",
    "                    continue\n",
    "                neighbors.append((i, j))\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def link_edges(strong_edges, weak_edges):\n",
    "    \"\"\" Find weak edges connected to strong edges and link them.\n",
    "\n",
    "    Iterate over each pixel in strong_edges and perform breadth first\n",
    "    search across the connected pixels in weak_edges to link them.\n",
    "    Here we consider a pixel (a, b) is connected to a pixel (c, d)\n",
    "    if (a, b) is one of the eight neighboring pixels of (c, d).\n",
    "\n",
    "    Args:\n",
    "        strong_edges: binary image of shape (H, W).\n",
    "        weak_edges: binary image of shape (H, W).\n",
    "    \n",
    "    Returns:\n",
    "        edges: numpy boolean array of shape(H, W).\n",
    "    \"\"\"\n",
    "\n",
    "    H, W = strong_edges.shape\n",
    "    indices = np.stack(np.nonzero(strong_edges)).T\n",
    "    edges = np.zeros((H, W), dtype=np.bool)\n",
    "\n",
    "    # Make new instances of arguments to leave the original\n",
    "    # references intact\n",
    "    weak_edges = np.copy(weak_edges)\n",
    "    edges = np.copy(strong_edges)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_strong = np.array(\n",
    "    [[1, 0, 0, 0],\n",
    "     [0, 0, 0, 0],\n",
    "     [0, 0, 0, 0],\n",
    "     [0, 0, 0, 1]],\n",
    "    dtype=np.bool\n",
    ")\n",
    "\n",
    "test_weak = np.array(\n",
    "    [[0, 0, 0, 1],\n",
    "     [0, 1, 0, 0],\n",
    "     [1, 0, 0, 0],\n",
    "     [0, 0, 1, 0]],\n",
    "    dtype=np.bool\n",
    ")\n",
    "\n",
    "test_linked = link_edges(test_strong, test_weak)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(test_strong)\n",
    "plt.title('Strong edges')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(test_weak)\n",
    "plt.title('Weak edges')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(test_linked)\n",
    "plt.title('Linked edges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = link_edges(strong_edges, weak_edges)\n",
    "\n",
    "plt.imshow(edges)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(edges)\n",
    "plt.axis('off')\n",
    "plt.title('Your result')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "reference = np.load('references/iguana_edge_tracking.npy')\n",
    "plt.imshow(reference)\n",
    "plt.axis('off')\n",
    "plt.title('Reference')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(edges ^ reference)\n",
    "plt.title('Difference')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Canny edge detector\n",
    "Implement **`canny`** below using the functions you have implemented so far. Test edge detector with different parameters.\n",
    "\n",
    "Here is an example of the output:\n",
    "\n",
    "![iguana_edges.png](iguana_edges.png)\n",
    "\n",
    "We provide the correct output and the difference between it and your result for debugging purposes.  If you see white spots in the Difference image, you should check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(img, kernel_size=5, sigma=1.4, high=20, low=15):\n",
    "    \"\"\" Implement canny edge detector by calling functions above.\n",
    "\n",
    "    Args:\n",
    "        img: binary image of shape (H, W).\n",
    "        kernel_size: int of size for kernel matrix.\n",
    "        sigma: float for calculating kernel.\n",
    "        high: high threshold for strong edges.\n",
    "        low: low threashold for weak edges.\n",
    "    Returns:\n",
    "        edge: numpy array of shape(H, W).\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load image\n",
    "img = io.imread('iguana.png', as_gray=True)\n",
    "\n",
    "# Run Canny edge detector\n",
    "edges = canny(img, kernel_size=5, sigma=1.4, high=0.03, low=0.02)\n",
    "print (edges.shape)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(edges)\n",
    "plt.axis('off')\n",
    "plt.title('Your result')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "reference = np.load('references/iguana_canny.npy')\n",
    "plt.imshow(reference)\n",
    "plt.axis('off')\n",
    "plt.title('Reference')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(edges ^ reference)\n",
    "plt.title('Difference')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Question (10 points)\n",
    "\n",
    "![1.7a.png](1.7a.png)\n",
    "\n",
    "**(a)** Suppose that the Canny edge detector successfully detects an edge in an image. The edge (see the figure above) is then rotated by θ, where the relationship between a point on the original edge $(x, y)$ and a point on the rotated edge $(x', y')$ is defined as\n",
    "\n",
    "$$\n",
    "x'=x\\cos{\\theta}\\\\\n",
    "y'=x\\sin{\\theta}\n",
    "$$\n",
    "\n",
    "Will the rotated edge be detected using the same Canny edge detector? Provide either a mathematical proof or a counter example.\n",
    "\n",
    "*-Hint 1: The detection of an edge by the Canny edge detector depends only on the magnitude of its derivative. The derivative at point (x, y) is determined by its components along the x and y directions. Think about how these magnitudes have changed because of the rotation.* <br>\n",
    "*-Hint 2: You can assume that (x,y) lies on the x-axis, i.e., y = 0. * <br>\n",
    "*-Hint 3: You can also assume that G_x(x, y) = 0. In other words, the gradient which is perpendicular to the direction of the unrotated edge at (x, y) only has a vertical component and thus only consists of G_y(x, y).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** Write your solution in this markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** After running the Canny edge detector on an image, you notice that long edges are broken into short segments separated by gaps. In addition, some spurious edges appear. For each of the two thresholds (low and high) used in hysteresis thresholding, explain how you would adjust the threshold (up or down) to address both problems. Assume that a setting exists for the two thresholds that produces the desired result. Briefly explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** Write your solution in this markdown cell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
